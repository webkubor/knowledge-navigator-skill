## [2026-01-16] 混合 RAG 架构 (Hybrid RAG Architecture) - 完整版 (Rev 2)

### 1. 核心理念
通过**“显式规则 (L0) + 私有内脑 (L1) + 官方外脑 (L2)”**的三层分发体系，实现 Token 效率与知识深度的完美平衡。

### 2. 三层使命与痛点解决

#### 🏛️ L0：显式规则 (Explicit Rules)
> **载体**: `index.md`, `vibe_rules.md`, `tech_stack.md`
> **核心使命**: **建立基准，消除幻觉。**

*   **解决什么痛点？**
    *   **上下文丢失**: AI 每次对话都忘了你的技术栈（Vue 还是 React？）。
    *   **行为不可控**: AI 写的代码风格飘忽不定（一会 TS 一会 JS）。
    *   **Token 浪费**: 每次都要重复输入几千字的 Prompt。
*   **一句话**: 它是 AI 的**“出厂设置”**，保证 AI 一上来就是“懂你”的状态。

#### 🛤️ L1：私有 RAG (Private Memory) - **优先检索**
> **载体**: ChromaDB (`scripts/ingest/`)
> **核心使命**: **沉淀经验，隐私回溯。**

*   **解决什么痛点？**
    *   **重复踩坑**: 上周修过的 Bug，今天 AI 又犯了。
    *   **个性化缺失**: AI 不知道你特定的业务逻辑（如“用户鉴权流程”）。
    *   **隐私安全**: 业务代码和密钥不能传给公有大模型微调。
*   **一句话**: 它是 AI 的**“私人日记”**，让 AI 优先回忆“我之前是怎么做的”。
*   **标记**: `[🧠 Local RAG]`

#### 🛤️ L2：官方 RAG (Official Knowledge) - **兜底查询**
> **载体**: MCP `searchKnowledgeBase` (腾讯云文档)
> **核心使命**: **即时查阅，扩展边界。**

*   **解决什么痛点？**
    *   **知识滞后**: AI 训练数据截止于 2023 年，不知道 2024 年的新 API。
    *   **准确性**: 引用人的言论而非 AI 的猜想（相对准确）。
*   **一句话**: 它是 AI 的**“在线字典”**，只有在自己没做过时才去查。
*   **标记**: `[🧠 Official RAG]`

### 3. 工程化亮点
*   **Token 节省**: 通过 L0 的分层注入，AI 只加载相关的 10% 规则，而非 100% 全量。
*   **优先级闭环**: **死规矩 (L0) > 私人经验 (L1) > 官方手册 (L2)**。
*   **隔离与隐私**: L0 和 L1 物理留存在本地，通过 MCP 桥接 L2，确保核心秘密不出本地。

---
> 评价：这形成了一套完整的、可观测的 AI 记忆闭环。